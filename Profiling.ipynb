{
   {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. IMPORTING LIBRARIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import zipfile\n",
    "import numpy as np\n",
    "import html\n",
    "import pandas as pd\n",
    "import xml.etree.ElementTree as ET\n",
    "import re\n",
    "import nltk\n",
    "import nltk.corpus\n",
    "from nltk.corpus import stopwords\n",
    "from string import punctuation\n",
    "from sklearn import svm\n",
    "from nltk.collocations import BigramCollocationFinder\n",
    "from nltk.metrics import BigramAssocMeasures\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. LOADING THE DATASET"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1 EXTRACTING THE DATA FILES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already Extracted...\n"
     ]
    }
   ],
   "source": [
    "cwd = os.getcwd() # current working directory\n",
    "cwd = cwd.replace(\"\\\\\",\"/\")\n",
    "if os.path.isdir(cwd+'/Data_for_Assignment2') == True: # checking if the file path exist or not\n",
    "    print(\"Files already Extracted...\")        # prints the file already exists\n",
    "else:\n",
    "    print(\"Extracting the files...\")         # extracting the files if the path doesn't exist\n",
    "    with zipfile.ZipFile(\"Assessment2_data.zip\",\"r\") as zip_ref:\n",
    "        zip_ref.extractall(\"./Data_for_Assignment2\")\n",
    "    print('\\n...')\n",
    "    with zipfile.ZipFile(\"./Data_for_Assignment2/Assessment2_data/data.zip\",\"r\") as zip_ref:\n",
    "        zip_ref.extractall(\"./Data_for_Assignment2/Assessment2_data/data\")\n",
    "        print('...')\n",
    "    print(\"...Done...\")    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### TRAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Filename</th>\n",
       "      <th>gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>d7d392835f50664fc079f0f388e147a0</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ee40b86368137b86f51806c9f105b34b</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>919bc742d9a22d65eab1f52b11656cab</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15b97a08d65f22d97ca685686510b6ae</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>affa98421ef5c46ca7c8f246e0a134c1</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Filename  gender\n",
       "0  d7d392835f50664fc079f0f388e147a0    male\n",
       "1  ee40b86368137b86f51806c9f105b34b  female\n",
       "2  919bc742d9a22d65eab1f52b11656cab    male\n",
       "3  15b97a08d65f22d97ca685686510b6ae  female\n",
       "4  affa98421ef5c46ca7c8f246e0a134c1  female"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train\n",
    "train_df = pd.read_csv('./Data_for_Assignment2/Assessment2_data/train_labels.csv') \n",
    "                                                  # extracting the train id and gender into a dataframe\n",
    "train_df.columns = ['Filename','gender']\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Filename</th>\n",
       "      <th>gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>d6b08022cdf758ead05e1c266649c393</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9a989cb04766d5a89a65e8912d448328</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2a1053a059d58fbafd3e782a8f7972c0</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6032537900368aca3d1546bd71ecabd1</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>d191280655be8108ec9928398ff5b563</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Filename  gender\n",
       "0  d6b08022cdf758ead05e1c266649c393    male\n",
       "1  9a989cb04766d5a89a65e8912d448328  female\n",
       "2  2a1053a059d58fbafd3e782a8f7972c0    male\n",
       "3  6032537900368aca3d1546bd71ecabd1    male\n",
       "4  d191280655be8108ec9928398ff5b563    male"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test\n",
    "test_df = pd.read_csv('test_labels.csv') # extracting the test id and gender into a dataframe\n",
    "test_df.columns = ['Filename','gender']\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train\n",
    "train_id = train_df[['Filename']].copy()       # storing the train id into a list\n",
    "\n",
    "# test\n",
    "test_id = test_df[['Filename']].copy()         # storing the test id inta a list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2 EXTRACTING THE TWEETS FROM FILES AND STORING IT INTO A DATAFRAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train\n",
    "train_tweets_dict = dict()                     # dictionary to store the id as key and tweets as value\n",
    "for i in range(len(train_id)):                 # tranversing through the train ids\n",
    "    filename = str(train_id.iloc[i][0])        # storing the filename into a variable\n",
    "                                               # storing the path of the filename from the folder\n",
    "    file_path = ('./Data_for_Assignment2/Assessment2_data/data/data/'+filename+'.xml')\n",
    "    tree = ET.parse(file_path)                 # using the parse function get the tree\n",
    "    root = tree.getroot()                      # using the getroot function get the corresponding root of the tree\n",
    "    tweets = []                                # list to store the tweets of the filename\n",
    "    for data in root.iter('document'):         # tranversing through the document tags\n",
    "        tweets.append(str(data.text).lower())  # converting into lowercase\n",
    "    train_tweets_dict[filename] = tweets       # storing the tweets of the id into dictionary\n",
    "\n",
    "tweet_df = pd.DataFrame(columns=['Filename','Tweet']) # creating a dataframe to store the contents from dictionary\n",
    "j = 0\n",
    "for filename,tweet in train_tweets_dict.items(): # adding the contents from dictionary into a dataframe\n",
    "    tweet_df.loc[j,'Filename'] = filename\n",
    "    tweet_df.loc[j,'Tweet'] = tweet\n",
    "    j = j + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test\n",
    "test_tweets_dict = dict()                      # dictionary to store the id as key and tweets as value\n",
    "for i in range(len(test_id)):                  # tranversing through the test ids\n",
    "    filename = str(test_id.iloc[i][0])         # storing the filename into a variable\n",
    "                                               # storing the path of the filename from the folder\n",
    "    file_path = ('./Data_for_Assignment2/Assessment2_data/data/data/'+filename+'.xml')\n",
    "    tree = ET.parse(file_path)                 # using the parse function get the tree\n",
    "    root = tree.getroot()                      # using the getroot function get the corresponding root of the tree\n",
    "    tweets = []                                # list to store the tweets of the filename\n",
    "    for data in root.iter('document'):         # tranversing through the document tags\n",
    "        tweets.append(str(data.text).lower())  # converting into lowercase\n",
    "    test_tweets_dict[filename] = tweets        # storing the tweets of the id into dictionary\n",
    "  \n",
    "  \n",
    "for filename,tweet in test_tweets_dict.items(): # adding the contents from dictionary into a dataframe\n",
    "    tweet_df.loc[j,'Filename'] = filename\n",
    "    tweet_df.loc[j,'Tweet'] = tweet\n",
    "    j = j + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. DATA PREPARATION AND EXTRACTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1 REMOVING STOPWORDS AND CLEANING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop = stopwords.words('english')               # stopwords list from nltk\n",
    "f = open('stopwords_en.txt','r')                # stopwords list from https://sites.google.com/site/kevinbouge/stopwords-lists \n",
    "stopword_list = f.readlines()                   # reading the stopwords file from local directory\n",
    "stopword_list = [x.strip() for x in stopword_list]\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_clean(text):                         # Function to perform cleaning of the tweets\n",
    "    special_charcter = punctuation              # storing the punctuation symbols into a variable\n",
    "    text = text.encode('ascii', 'ignore').decode('ascii') # removing all the emoji   \n",
    "    text = html.unescape(text)                  # removing the escaping characters  \n",
    "    text = text.split()                         # spliting the text into a list\n",
    "    text = [word for word in text if word not in stopword_list]\n",
    "    text = \" \".join(text)\n",
    "    text = re.sub(r\"http\\S+\", \"\", text)         # removing the URL links\n",
    "    text = re.sub('#\\S+','',text)               # removing hastags\n",
    "    text = re.sub('@\\S+','',text)               # removing personal tag\n",
    "    text  = \"\".join([char for char in text if char not in special_charcter]) # removing the punctuations\n",
    "    text = re.sub('[0-9]+', '', text)           # removing the numbers\n",
    "    text = re.sub('[^A-Za-z]',' ',text)         # removing everything except alphabets\n",
    "    text  = \"\".join([char for char in text if char not in special_charcter]) # removing the punctuations\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# train and test data\n",
    "df = tweet_df.copy()                            # creating a copy of the dataframe\n",
    "tweet_df['tweet_punc'] = ''                     # adding a new column to store the cleaned tweets \n",
    "\n",
    "for row in range(len(df)):                      # tranversing through the dataframe\n",
    "    tweets = []                                 # list to store the cleaned tweets\n",
    "    filename = df.loc[row,'Filename']           # storing the filename\n",
    "    for x in df.loc[row,'Tweet']:               # tranversing through tweets of the corresponding filename\n",
    "        text = str(x)                           # converting the datatype to string\n",
    "        x = [word for word in text.split() if word not in stop] # removing the stopwords(nltk)\n",
    "        x = ' '.join(x)                         # making it into a string\n",
    "        tweets.append(remove_clean(str(x)))     # cleaning the text using the function remove_clean\n",
    "        \n",
    "    tweet_df.loc[row,'tweet_punc'] = tweets     # adding the cleaned text to the new column \"tweet_punc\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3600"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tweet_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Filename</th>\n",
       "      <th>Tweet</th>\n",
       "      <th>tweet_punc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>d7d392835f50664fc079f0f388e147a0</td>\n",
       "      <td>[@csiferroscan youch! good things to know! is ...</td>\n",
       "      <td>[ youch good things know sort stuff repairable...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ee40b86368137b86f51806c9f105b34b</td>\n",
       "      <td>[donald the menace #thankscomey  https://t.co/...</td>\n",
       "      <td>[donald menace  , return national greatness , ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>919bc742d9a22d65eab1f52b11656cab</td>\n",
       "      <td>[this seems super sketch / too good to be true...</td>\n",
       "      <td>[super sketch  good true  legit, invisible rop...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15b97a08d65f22d97ca685686510b6ae</td>\n",
       "      <td>[just some texts with my dad about our saturda...</td>\n",
       "      <td>[texts dad saturday night plans   tells , feel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>affa98421ef5c46ca7c8f246e0a134c1</td>\n",
       "      <td>[irrevocably love this talented human and so p...</td>\n",
       "      <td>[irrevocably love talented human proudtotes sl...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Filename  \\\n",
       "0  d7d392835f50664fc079f0f388e147a0   \n",
       "1  ee40b86368137b86f51806c9f105b34b   \n",
       "2  919bc742d9a22d65eab1f52b11656cab   \n",
       "3  15b97a08d65f22d97ca685686510b6ae   \n",
       "4  affa98421ef5c46ca7c8f246e0a134c1   \n",
       "\n",
       "                                               Tweet  \\\n",
       "0  [@csiferroscan youch! good things to know! is ...   \n",
       "1  [donald the menace #thankscomey  https://t.co/...   \n",
       "2  [this seems super sketch / too good to be true...   \n",
       "3  [just some texts with my dad about our saturda...   \n",
       "4  [irrevocably love this talented human and so p...   \n",
       "\n",
       "                                          tweet_punc  \n",
       "0  [ youch good things know sort stuff repairable...  \n",
       "1  [donald menace  , return national greatness , ...  \n",
       "2  [super sketch  good true  legit, invisible rop...  \n",
       "3  [texts dad saturday night plans   tells , feel...  \n",
       "4  [irrevocably love talented human proudtotes sl...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2 CONVERTING TO TOKENS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenization(text):                          # function to perform tokenizations       \n",
    "    text = re.split('\\W+', text)                 # performing tokenization using regex\n",
    "    return text                                  # returning the tokens list of words  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train and test data\n",
    "df = tweet_df.copy()                             # creating a copy of the dataframe\n",
    "tweet_df['tweet_token'] = ''                     # adding a new column to store the cleaned tweets \n",
    "\n",
    "for row in range(len(df)):                       # tranversing through the dataframe\n",
    "    tweets = []                                  # list to store the tokenized tweets\n",
    "    for x in df.loc[row,'tweet_punc']:           # tranversing through tweets of the corresponding filename\n",
    "        tweets.extend(tokenization(str(x)))      # converting the string into tokens\n",
    "    tweets = [word for word in tweets if word != ''] # removing '' from list of tokens\n",
    "    tweet_df.loc[row,'tweet_token'] = tweets     # adding the tokenized tweets into new column \" tweet_token \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3600"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tweet_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Filename</th>\n",
       "      <th>Tweet</th>\n",
       "      <th>tweet_punc</th>\n",
       "      <th>tweet_token</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>d7d392835f50664fc079f0f388e147a0</td>\n",
       "      <td>[@csiferroscan youch! good things to know! is ...</td>\n",
       "      <td>[ youch good things know sort stuff repairable...</td>\n",
       "      <td>[youch, good, things, know, sort, stuff, repai...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ee40b86368137b86f51806c9f105b34b</td>\n",
       "      <td>[donald the menace #thankscomey  https://t.co/...</td>\n",
       "      <td>[donald menace  , return national greatness , ...</td>\n",
       "      <td>[donald, menace, return, national, greatness, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>919bc742d9a22d65eab1f52b11656cab</td>\n",
       "      <td>[this seems super sketch / too good to be true...</td>\n",
       "      <td>[super sketch  good true  legit, invisible rop...</td>\n",
       "      <td>[super, sketch, good, true, legit, invisible, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15b97a08d65f22d97ca685686510b6ae</td>\n",
       "      <td>[just some texts with my dad about our saturda...</td>\n",
       "      <td>[texts dad saturday night plans   tells , feel...</td>\n",
       "      <td>[texts, dad, saturday, night, plans, tells, fe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>affa98421ef5c46ca7c8f246e0a134c1</td>\n",
       "      <td>[irrevocably love this talented human and so p...</td>\n",
       "      <td>[irrevocably love talented human proudtotes sl...</td>\n",
       "      <td>[irrevocably, love, talented, human, proudtote...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Filename  \\\n",
       "0  d7d392835f50664fc079f0f388e147a0   \n",
       "1  ee40b86368137b86f51806c9f105b34b   \n",
       "2  919bc742d9a22d65eab1f52b11656cab   \n",
       "3  15b97a08d65f22d97ca685686510b6ae   \n",
       "4  affa98421ef5c46ca7c8f246e0a134c1   \n",
       "\n",
       "                                               Tweet  \\\n",
       "0  [@csiferroscan youch! good things to know! is ...   \n",
       "1  [donald the menace #thankscomey  https://t.co/...   \n",
       "2  [this seems super sketch / too good to be true...   \n",
       "3  [just some texts with my dad about our saturda...   \n",
       "4  [irrevocably love this talented human and so p...   \n",
       "\n",
       "                                          tweet_punc  \\\n",
       "0  [ youch good things know sort stuff repairable...   \n",
       "1  [donald menace  , return national greatness , ...   \n",
       "2  [super sketch  good true  legit, invisible rop...   \n",
       "3  [texts dad saturday night plans   tells , feel...   \n",
       "4  [irrevocably love talented human proudtotes sl...   \n",
       "\n",
       "                                         tweet_token  \n",
       "0  [youch, good, things, know, sort, stuff, repai...  \n",
       "1  [donald, menace, return, national, greatness, ...  \n",
       "2  [super, sketch, good, true, legit, invisible, ...  \n",
       "3  [texts, dad, saturday, night, plans, tells, fe...  \n",
       "4  [irrevocably, love, talented, human, proudtote...  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3 REMOVING WORDS WITH WORD COUNT LESS THAN 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_dict = dict()                       # creating to dictionary\n",
    "for row in range(len(tweet_df)):         # tranversing through the dataframe\n",
    "    word_list_row = tweet_df.loc[row,'tweet_token'] # storing the tokens of a filename into a variable\n",
    "    for eachword in word_list_row:       # tranversing each word list\n",
    "        if eachword in word_dict.keys(): # checking if the word is in dictionary\n",
    "            word_dict[eachword] += 1     # if the word is already in the dictionary increment the counter\n",
    "        else:                            # word is not in dictionary\n",
    "            word_dict[eachword] = 1      # assign 1 as its value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "not_required_words = []                  # list to store unwanted words\n",
    "for word,count in word_dict.items():     # tranversing through word dictionary\n",
    "    if count < 2:                        # checking if the word count is less than 2\n",
    "        not_required_words.append(word)  # adding the unwanted word into the list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train and test data\n",
    "tweet_df['least_freq_remove'] = ''       # adding new column into the dataframe\n",
    "least_frequenct_words_list = set(not_required_words) # converting the list of unwanted words to set and storing it\n",
    "for row in range(len(tweet_df)):         # tranversing through the dataframe\n",
    "    word_list = set(tweet_df.loc[row,'tweet_token']) # converting the words of filename into a set datatype\n",
    "    new_word_list = set()                # set variable to store\n",
    "    new_word_list = word_list - least_frequenct_words_list # removing all the unwanted words\n",
    "    change_type = list(new_word_list)    # changing the datatype to list\n",
    "    tweet_df.loc[row,'least_freq_remove'] = change_type    # storing the new set of words into the new column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3600"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tweet_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Filename</th>\n",
       "      <th>Tweet</th>\n",
       "      <th>tweet_punc</th>\n",
       "      <th>tweet_token</th>\n",
       "      <th>least_freq_remove</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>d7d392835f50664fc079f0f388e147a0</td>\n",
       "      <td>[@csiferroscan youch! good things to know! is ...</td>\n",
       "      <td>[ youch good things know sort stuff repairable...</td>\n",
       "      <td>[youch, good, things, know, sort, stuff, repai...</td>\n",
       "      <td>[supplies, skygo, earl, knocked, inches, adult...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ee40b86368137b86f51806c9f105b34b</td>\n",
       "      <td>[donald the menace #thankscomey  https://t.co/...</td>\n",
       "      <td>[donald menace  , return national greatness , ...</td>\n",
       "      <td>[donald, menace, return, national, greatness, ...</td>\n",
       "      <td>[shocking, daily, events, necessary, voice, fo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>919bc742d9a22d65eab1f52b11656cab</td>\n",
       "      <td>[this seems super sketch / too good to be true...</td>\n",
       "      <td>[super sketch  good true  legit, invisible rop...</td>\n",
       "      <td>[super, sketch, good, true, legit, invisible, ...</td>\n",
       "      <td>[destroy, committing, west, yourself, invisibl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15b97a08d65f22d97ca685686510b6ae</td>\n",
       "      <td>[just some texts with my dad about our saturda...</td>\n",
       "      <td>[texts dad saturday night plans   tells , feel...</td>\n",
       "      <td>[texts, dad, saturday, night, plans, tells, fe...</td>\n",
       "      <td>[forward, yday, contribution, rod, driving, th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>affa98421ef5c46ca7c8f246e0a134c1</td>\n",
       "      <td>[irrevocably love this talented human and so p...</td>\n",
       "      <td>[irrevocably love talented human proudtotes sl...</td>\n",
       "      <td>[irrevocably, love, talented, human, proudtote...</td>\n",
       "      <td>[god, spoilers, comedy, suzi, hour, trump, vel...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Filename  \\\n",
       "0  d7d392835f50664fc079f0f388e147a0   \n",
       "1  ee40b86368137b86f51806c9f105b34b   \n",
       "2  919bc742d9a22d65eab1f52b11656cab   \n",
       "3  15b97a08d65f22d97ca685686510b6ae   \n",
       "4  affa98421ef5c46ca7c8f246e0a134c1   \n",
       "\n",
       "                                               Tweet  \\\n",
       "0  [@csiferroscan youch! good things to know! is ...   \n",
       "1  [donald the menace #thankscomey  https://t.co/...   \n",
       "2  [this seems super sketch / too good to be true...   \n",
       "3  [just some texts with my dad about our saturda...   \n",
       "4  [irrevocably love this talented human and so p...   \n",
       "\n",
       "                                          tweet_punc  \\\n",
       "0  [ youch good things know sort stuff repairable...   \n",
       "1  [donald menace  , return national greatness , ...   \n",
       "2  [super sketch  good true  legit, invisible rop...   \n",
       "3  [texts dad saturday night plans   tells , feel...   \n",
       "4  [irrevocably love talented human proudtotes sl...   \n",
       "\n",
       "                                         tweet_token  \\\n",
       "0  [youch, good, things, know, sort, stuff, repai...   \n",
       "1  [donald, menace, return, national, greatness, ...   \n",
       "2  [super, sketch, good, true, legit, invisible, ...   \n",
       "3  [texts, dad, saturday, night, plans, tells, fe...   \n",
       "4  [irrevocably, love, talented, human, proudtote...   \n",
       "\n",
       "                                   least_freq_remove  \n",
       "0  [supplies, skygo, earl, knocked, inches, adult...  \n",
       "1  [shocking, daily, events, necessary, voice, fo...  \n",
       "2  [destroy, committing, west, yourself, invisibl...  \n",
       "3  [forward, yday, contribution, rod, driving, th...  \n",
       "4  [god, spoilers, comedy, suzi, hour, trump, vel...  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.4 INTRODUCING BI-GRAMS "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train and test data\n",
    "tweet_df['bigrams'] = ''           # adding new column into the dataframe\n",
    "for row in range(len(tweet_df)):   # tranversing through the dataframe\n",
    "    tokens = []                    # list to store the tokens\n",
    "    tokens = tweet_df.loc[row,'least_freq_remove']             # storing the output got from previous function\n",
    "    bigram_finder = BigramCollocationFinder.from_words(tokens) # creates all possible bigrams using the supplied tokens\n",
    "    bigrams = bigram_finder.nbest(BigramAssocMeasures.chi_sq, 10) # chooses the best 10 bigrams\n",
    "    k = []                         # list to store the bigrams \n",
    "    for bigram_tuple in bigrams:   # tranversing the bigrams list\n",
    "        x = \"%s %s\" % bigram_tuple # combining the bigrams in tuple format to single string separated by space\n",
    "        k.append(x)                # appending it to the list\n",
    "    tokens.extend(k)               # adding to list \n",
    "    tweet_df.loc[row,'bigrams'] = tokens  # adding the tokens(unigrams + bigrams) into the new column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3600"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tweet_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Filename</th>\n",
       "      <th>Tweet</th>\n",
       "      <th>tweet_punc</th>\n",
       "      <th>tweet_token</th>\n",
       "      <th>least_freq_remove</th>\n",
       "      <th>bigrams</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>d7d392835f50664fc079f0f388e147a0</td>\n",
       "      <td>[@csiferroscan youch! good things to know! is ...</td>\n",
       "      <td>[ youch good things know sort stuff repairable...</td>\n",
       "      <td>[youch, good, things, know, sort, stuff, repai...</td>\n",
       "      <td>[supplies, skygo, earl, knocked, inches, adult...</td>\n",
       "      <td>[supplies, skygo, earl, knocked, inches, adult...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ee40b86368137b86f51806c9f105b34b</td>\n",
       "      <td>[donald the menace #thankscomey  https://t.co/...</td>\n",
       "      <td>[donald menace  , return national greatness , ...</td>\n",
       "      <td>[donald, menace, return, national, greatness, ...</td>\n",
       "      <td>[shocking, daily, events, necessary, voice, fo...</td>\n",
       "      <td>[shocking, daily, events, necessary, voice, fo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>919bc742d9a22d65eab1f52b11656cab</td>\n",
       "      <td>[this seems super sketch / too good to be true...</td>\n",
       "      <td>[super sketch  good true  legit, invisible rop...</td>\n",
       "      <td>[super, sketch, good, true, legit, invisible, ...</td>\n",
       "      <td>[destroy, committing, west, yourself, invisibl...</td>\n",
       "      <td>[destroy, committing, west, yourself, invisibl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15b97a08d65f22d97ca685686510b6ae</td>\n",
       "      <td>[just some texts with my dad about our saturda...</td>\n",
       "      <td>[texts dad saturday night plans   tells , feel...</td>\n",
       "      <td>[texts, dad, saturday, night, plans, tells, fe...</td>\n",
       "      <td>[forward, yday, contribution, rod, driving, th...</td>\n",
       "      <td>[forward, yday, contribution, rod, driving, th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>affa98421ef5c46ca7c8f246e0a134c1</td>\n",
       "      <td>[irrevocably love this talented human and so p...</td>\n",
       "      <td>[irrevocably love talented human proudtotes sl...</td>\n",
       "      <td>[irrevocably, love, talented, human, proudtote...</td>\n",
       "      <td>[god, spoilers, comedy, suzi, hour, trump, vel...</td>\n",
       "      <td>[god, spoilers, comedy, suzi, hour, trump, vel...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Filename  \\\n",
       "0  d7d392835f50664fc079f0f388e147a0   \n",
       "1  ee40b86368137b86f51806c9f105b34b   \n",
       "2  919bc742d9a22d65eab1f52b11656cab   \n",
       "3  15b97a08d65f22d97ca685686510b6ae   \n",
       "4  affa98421ef5c46ca7c8f246e0a134c1   \n",
       "\n",
       "                                               Tweet  \\\n",
       "0  [@csiferroscan youch! good things to know! is ...   \n",
       "1  [donald the menace #thankscomey  https://t.co/...   \n",
       "2  [this seems super sketch / too good to be true...   \n",
       "3  [just some texts with my dad about our saturda...   \n",
       "4  [irrevocably love this talented human and so p...   \n",
       "\n",
       "                                          tweet_punc  \\\n",
       "0  [ youch good things know sort stuff repairable...   \n",
       "1  [donald menace  , return national greatness , ...   \n",
       "2  [super sketch  good true  legit, invisible rop...   \n",
       "3  [texts dad saturday night plans   tells , feel...   \n",
       "4  [irrevocably love talented human proudtotes sl...   \n",
       "\n",
       "                                         tweet_token  \\\n",
       "0  [youch, good, things, know, sort, stuff, repai...   \n",
       "1  [donald, menace, return, national, greatness, ...   \n",
       "2  [super, sketch, good, true, legit, invisible, ...   \n",
       "3  [texts, dad, saturday, night, plans, tells, fe...   \n",
       "4  [irrevocably, love, talented, human, proudtote...   \n",
       "\n",
       "                                   least_freq_remove  \\\n",
       "0  [supplies, skygo, earl, knocked, inches, adult...   \n",
       "1  [shocking, daily, events, necessary, voice, fo...   \n",
       "2  [destroy, committing, west, yourself, invisibl...   \n",
       "3  [forward, yday, contribution, rod, driving, th...   \n",
       "4  [god, spoilers, comedy, suzi, hour, trump, vel...   \n",
       "\n",
       "                                             bigrams  \n",
       "0  [supplies, skygo, earl, knocked, inches, adult...  \n",
       "1  [shocking, daily, events, necessary, voice, fo...  \n",
       "2  [destroy, committing, west, yourself, invisibl...  \n",
       "3  [forward, yday, contribution, rod, driving, th...  \n",
       "4  [god, spoilers, comedy, suzi, hour, trump, vel...  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.6 CONVERTING TOKENS INTO SENTENCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train and test data\n",
    "tweet_df['Clean_text'] = ''                     # adding the new column\n",
    "for row in range(len(tweet_df)):                # tranversing the dataframe\n",
    "    sen = ''                                    # creating the empty string\n",
    "    sen = ' '.join(tweet_df.loc[row,'bigrams']) # converting the list of tokens into a sentence\n",
    "    tweet_df.loc[row,'Clean_text'] = sen        # adding the sentence into dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3600"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tweet_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.7 SPLIT THE 3600 FILES INTO TRAIN AND TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = ['Filename'] # list variable storing the column name\n",
    "test_tweet_df = pd.DataFrame(columns=column_names)  # creating the a dataframe using the column names variable for test\n",
    "train_tweet_df = pd.DataFrame(columns=column_names) # creating the a dataframe using the column names variable for train\n",
    "\n",
    "for names in range(len(test_id)):  # tranversing through test ids\n",
    "    test_tweet_df.loc[names,'Filename'] = test_id.loc[names,'Filename']   # adding the test id to new dataframe\n",
    "    \n",
    "for names in range(len(train_id)): # tranversing through train ids\n",
    "    train_tweet_df.loc[names,'Filename'] = train_id.loc[names,'Filename'] # adding the train id to new dataframe    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3100"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# spliting the train data from the tweet_df \n",
    "train = pd.merge(train_tweet_df,tweet_df,on='Filename',how='inner') \n",
    "train = pd.merge(train,train_df,on='Filename',how='inner')\n",
    "len(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "500"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# spliting the test data from the tweet_df \n",
    "test = pd.merge(test_tweet_df,tweet_df,on='Filename',how='inner')\n",
    "test = pd.merge(test,test_df,on='Filename',how='inner')\n",
    "len(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.8 PERFORMING TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1)  # setting random seed for reproducing same the results\n",
    "tfidf_vect = TfidfVectorizer(max_features=None) \n",
    "tfidf_vect.fit(train['Clean_text'])  # fitting the train data to TF-IDF\n",
    "\n",
    "# performing transform TF-IDF on train and test data\n",
    "x_train = tfidf_vect.transform(train['Clean_text'])     \n",
    "y_train = np.asarray(train[['gender']])\n",
    "\n",
    "x_test = tfidf_vect.transform(test['Clean_text'])\n",
    "y_test = np.asarray(test[['gender']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. BUILDING CLASSIFIER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Support Vector Machine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Before HyperTuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\utils\\validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model: 79.80000000000001\n"
     ]
    }
   ],
   "source": [
    "SVM = svm.SVC(C=10,kernel='linear',degree=3,gamma=1) # building the svm model\n",
    "\n",
    "SVM.fit(x_train,y_train)  # fitting the model or training the model using train data\n",
    "\n",
    "predictions_svm = SVM.predict(x_test) # predicting the gender for test data\n",
    "\n",
    "print(\"Accuracy of the model:\",accuracy_score(predictions_svm,y_test)*100) # printing the accuracy score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Finding Hyper Parameters for SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uncomment the code to find the hyper parameters for SVM (this will take time)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 64 candidates, totalling 320 fits\n",
      "[CV] C=0.1, gamma=1, kernel=rbf ......................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "C:\\Users\\USER\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\utils\\validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ....................... C=0.1, gamma=1, kernel=rbf, total=  39.8s\n",
      "[CV] C=0.1, gamma=1, kernel=rbf ......................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   39.7s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ....................... C=0.1, gamma=1, kernel=rbf, total=  39.3s\n",
      "[CV] C=0.1, gamma=1, kernel=rbf ......................................\n",
      "[CV] ....................... C=0.1, gamma=1, kernel=rbf, total=  37.8s\n",
      "[CV] C=0.1, gamma=1, kernel=rbf ......................................\n",
      "[CV] ....................... C=0.1, gamma=1, kernel=rbf, total=  39.1s\n",
      "[CV] C=0.1, gamma=1, kernel=rbf ......................................\n",
      "[CV] ....................... C=0.1, gamma=1, kernel=rbf, total=  34.6s\n",
      "[CV] C=0.1, gamma=1, kernel=poly .....................................\n",
      "[CV] ...................... C=0.1, gamma=1, kernel=poly, total=  32.5s\n",
      "[CV] C=0.1, gamma=1, kernel=poly .....................................\n",
      "[CV] ...................... C=0.1, gamma=1, kernel=poly, total=  38.8s\n",
      "[CV] C=0.1, gamma=1, kernel=poly .....................................\n",
      "[CV] ...................... C=0.1, gamma=1, kernel=poly, total=  33.2s\n",
      "[CV] C=0.1, gamma=1, kernel=poly .....................................\n",
      "[CV] ...................... C=0.1, gamma=1, kernel=poly, total=  33.2s\n",
      "[CV] C=0.1, gamma=1, kernel=poly .....................................\n",
      "[CV] ...................... C=0.1, gamma=1, kernel=poly, total=  33.0s\n",
      "[CV] C=0.1, gamma=1, kernel=sigmoid ..................................\n",
      "[CV] ................... C=0.1, gamma=1, kernel=sigmoid, total=  29.9s\n",
      "[CV] C=0.1, gamma=1, kernel=sigmoid ..................................\n",
      "[CV] ................... C=0.1, gamma=1, kernel=sigmoid, total=  30.2s\n",
      "[CV] C=0.1, gamma=1, kernel=sigmoid ..................................\n",
      "[CV] ................... C=0.1, gamma=1, kernel=sigmoid, total=  29.2s\n",
      "[CV] C=0.1, gamma=1, kernel=sigmoid ..................................\n",
      "[CV] ................... C=0.1, gamma=1, kernel=sigmoid, total=  35.6s\n",
      "[CV] C=0.1, gamma=1, kernel=sigmoid ..................................\n",
      "[CV] ................... C=0.1, gamma=1, kernel=sigmoid, total=  36.8s\n",
      "[CV] C=0.1, gamma=1, kernel=linear ...................................\n"
     ]
    }
   ],
   "source": [
    "# from sklearn.svm import SVC\n",
    "# from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# param_grid = {'C': [0.1,1, 10, 100], 'gamma': [1,0.1,0.01,0.001],'kernel': ['rbf', 'poly', 'sigmoid','linear']}\n",
    "\n",
    "# grid = GridSearchCV(SVC(),param_grid,refit=True,verbose=2)\n",
    "\n",
    "# grid.fit(x_train,y_train)\n",
    "\n",
    "# print(grid.best_estimator_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SVM with the parameters obtained from GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model: 82.39999999999999\n"
     ]
    }
   ],
   "source": [
    "SVM = svm.SVC(C=100, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
    "    decision_function_shape='ovr', degree=3, gamma=1, kernel='rbf', max_iter=-1,\n",
    "    probability=False, random_state=None, shrinking=True, tol=0.001,\n",
    "    verbose=False)                       # building the svm model using parameters obtained from GridSearchCV\n",
    "\n",
    "SVM.fit(x_train,y_train)       # fitting the model or training the model using train data\n",
    "  \n",
    "predictions_svm = SVM.predict(x_test)    # predicting the gender for test data\n",
    "\n",
    "print(\"Accuracy of the model:\",accuracy_score(predictions_svm,y_test)*100) # printing the accuracy score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.824"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(test['gender'] == predictions_svm)/500 # finding the accuracy using the test_labels provided from moodle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we got the highest accuracy of 82.4%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Predicting the gender and saving it into a CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "SVM = svm.SVC(C=100, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
    "    decision_function_shape='ovr', degree=3, gamma=1, kernel='rbf', max_iter=-1,\n",
    "    probability=False, random_state=None, shrinking=True, tol=0.001,\n",
    "    verbose=False)                       # building the svm model using parameters obtained from GridSearchCV\n",
    "\n",
    "SVM.fit(x_train,y_train)       # fitting the model or training the model using train data\n",
    "  \n",
    "predictions_svm = SVM.predict(x_test)    # predicting the gender for test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = test.copy()   # creating a copy of the test dataframe\n",
    "df.loc[:,'gender'] = pd.Series(predictions_svm) # adding the predicted gender to dataframe\n",
    "df=df[['Filename','gender']]  # filter out the columns\n",
    "df.columns = ['id','gender']  # rename the filename column to id\n",
    "df.to_csv('predict_label.csv',index=False) # saving the test_labels.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## REFERENCES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[1] stopwords english : https://sites.google.com/site/kevinbouge/stopwords-lists <br>\n",
    "[2] Model Building    : https://scikit-learn.org/stable/  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
